{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import os \n",
    "import numpy as np \n",
    "from random import shuffle \n",
    "from tqdm import tqdm\n",
    "import tflearn \n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d \n",
    "from tflearn.layers.core import input_data, dropout, fully_connected \n",
    "from tflearn.layers.estimator import regression \n",
    "from keras import Sequential\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir(\"/home/aniketh/Documents/fog-parkinsons/rps/120s/individual_data\")\n",
    "data_sub_1 = np.load(\"data_sub_1.npy\")\n",
    "data_sub_2 = np.load(\"data_sub_2.npy\")\n",
    "data_sub_3 = np.load(\"data_sub_3.npy\")\n",
    "data_sub_4 = np.load(\"data_sub_4.npy\")\n",
    "data_sub_5 = np.load(\"data_sub_5.npy\")\n",
    "data_sub_6 = np.load(\"data_sub_6.npy\")\n",
    "data_sub_7 = np.load(\"data_sub_7.npy\")\n",
    "data_sub_8 = np.load(\"data_sub_8.npy\")\n",
    "data_sub_9 = np.load(\"data_sub_9.npy\")\n",
    "data_sub_10 = np.load(\"data_sub_10.npy\")\n",
    "\n",
    "labels_sub_1 = np.load(\"labels_sub_1.npy\")\n",
    "labels_sub_2 = np.load(\"labels_sub_2.npy\")\n",
    "labels_sub_3 = np.load(\"labels_sub_3.npy\")\n",
    "labels_sub_4 = np.load(\"labels_sub_4.npy\")\n",
    "labels_sub_5 = np.load(\"labels_sub_5.npy\")\n",
    "labels_sub_6 = np.load(\"labels_sub_6.npy\")\n",
    "labels_sub_7 = np.load(\"labels_sub_7.npy\")\n",
    "labels_sub_8 = np.load(\"labels_sub_8.npy\")\n",
    "labels_sub_9 = np.load(\"labels_sub_9.npy\")\n",
    "labels_sub_10 = np.load(\"labels_sub_10.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 1 as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of unique values of the said array:\n",
      "[[   0    1]\n",
      " [1976 1462]]\n",
      "Epoch 1/1\n",
      "3438/3438 [==============================] - 30s 9ms/step - loss: 9.1629 - acc: 0.4252\n",
      "517/517 [==============================] - 2s 5ms/step\n",
      "8.048283254154896 0.49516441051918486\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "unique_elements, counts_elements = np.unique(labels_training, return_counts=True)\n",
    "print(\"Frequency of unique values of the said array:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=20, epochs=1,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_sub_1, y=labels_sub_1, batch_size=20, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2749/2749 [==============================] - 35s 13ms/step - loss: 0.4657 - acc: 0.7577\n",
      "689/689 [==============================] - 4s 5ms/step\n",
      "0.24818043948214702 0.8722786707438648\n",
      "[[317  79]\n",
      " [  9 284]]\n",
      "sens and spec is:\n",
      "0.9692832764505119 0.8005050505050505\n",
      "Epoch 1/1\n",
      "2750/2750 [==============================] - 36s 13ms/step - loss: 0.4302 - acc: 0.7975\n",
      "688/688 [==============================] - 4s 5ms/step\n",
      "0.22870537904718943 0.9229651194628935\n",
      "[[380  15]\n",
      " [ 38 255]]\n",
      "sens and spec is:\n",
      "0.8703071672354948 0.9620253164556962\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 36s 13ms/step - loss: 0.4103 - acc: 0.7993\n",
      "687/687 [==============================] - 4s 5ms/step\n",
      "0.27117323973654794 0.8806404698710601\n",
      "[[391   4]\n",
      " [ 78 214]]\n",
      "sens and spec is:\n",
      "0.7328767123287672 0.9898734177215189\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 36s 13ms/step - loss: 0.4013 - acc: 0.8015\n",
      "687/687 [==============================] - 4s 6ms/step\n",
      "0.21786302470993874 0.8995633236792757\n",
      "[[329  66]\n",
      " [  3 289]]\n",
      "sens and spec is:\n",
      "0.9897260273972602 0.8329113924050633\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 37s 13ms/step - loss: 0.3766 - acc: 0.8212\n",
      "687/687 [==============================] - 4s 6ms/step\n",
      "0.15922769281912014 0.9417758400089703\n",
      "[[370  25]\n",
      " [ 15 277]]\n",
      "sens and spec is:\n",
      "0.9486301369863014 0.9367088607594937\n",
      "517/517 [==============================] - 3s 5ms/step\n",
      "sensitivity, specificity and accuracy of models:\n",
      "0.9021646640796671\n",
      "0.9044048075693645\n",
      "0.903444684753213\n",
      "[[226  35]\n",
      " [216  40]]\n",
      "sensitivity, specificity and accuracy of subject:\n",
      "0.15625\n",
      "0.8659003831417624\n",
      "0.514506775417457\n"
     ]
    }
   ],
   "source": [
    "sens_l = []\n",
    "spec_l = []\n",
    "acc_l = []\n",
    "\n",
    "data_training = np.concatenate((data_sub_2, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "    y_pred = model.predict(data_test, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    sens_l.append(sens)\n",
    "    spec = tn/(tn+fp)\n",
    "    spec_l.append(spec)\n",
    "    acc_l.append(acc)\n",
    "    print(confusion_matrix(labels_test,y_pred))\n",
    "    print(\"sens and spec is:\")\n",
    "    print(sens, spec)\n",
    "    \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_1, y=labels_sub_1, batch_size=5, verbose=1)\n",
    "    y_pred = model.predict(data_sub_1, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_sub_1,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    print(\"sensitivity, specificity and accuracy of models:\")\n",
    "    print(np.mean(sens_l))\n",
    "    print(np.mean(spec_l))\n",
    "    print(np.mean(acc_l))\n",
    "    print(confusion_matrix(labels_sub_1,y_pred))\n",
    "    print(\"sensitivity, specificity and accuracy of subject:\")\n",
    "    print(sens)\n",
    "    print(spec)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 layers cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3438/3438 [==============================] - 39s 11ms/step - loss: 9.1629 - acc: 0.4252\n",
      "Epoch 2/2\n",
      "3438/3438 [==============================] - 38s 11ms/step - loss: 9.1629 - acc: 0.4252\n",
      "517/517 [==============================] - 3s 6ms/step\n",
      "8.048283254154896 0.49516441051918486\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 10, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=20, epochs=1,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_sub_1, y=labels_sub_1, batch_size=20, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2749/2749 [==============================] - 34s 12ms/step - loss: 0.4520 - acc: 0.7636\n",
      "689/689 [==============================] - 5s 7ms/step\n",
      "0.35940811724681815 0.8519593675354569\n",
      "[[376  20]\n",
      " [ 82 211]]\n",
      "sens and spec is:\n",
      "0.7201365187713311 0.9494949494949495\n",
      "Epoch 1/1\n",
      "2750/2750 [==============================] - 33s 12ms/step - loss: 0.4766 - acc: 0.7284\n",
      "688/688 [==============================] - 5s 7ms/step\n",
      "0.3432843771649438 0.8808139589680142\n",
      "[[352  43]\n",
      " [ 39 254]]\n",
      "sens and spec is:\n",
      "0.8668941979522184 0.8911392405063291\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 34s 12ms/step - loss: 0.5110 - acc: 0.7041\n",
      "687/687 [==============================] - 5s 7ms/step\n",
      "0.4002058076315724 0.8180494976963365\n",
      "[[339  56]\n",
      " [ 69 223]]\n",
      "sens and spec is:\n",
      "0.7636986301369864 0.8582278481012658\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 34s 12ms/step - loss: 0.5166 - acc: 0.7019\n",
      "687/687 [==============================] - 5s 7ms/step\n",
      "0.3699795338975908 0.8471615800777724\n",
      "[[315  80]\n",
      " [ 25 267]]\n",
      "sens and spec is:\n",
      "0.9143835616438356 0.7974683544303798\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 35s 13ms/step - loss: 0.5224 - acc: 0.7045\n",
      "687/687 [==============================] - 5s 7ms/step\n",
      "0.42793708511794615 0.7787481878261899\n",
      "[[254 141]\n",
      " [ 11 281]]\n",
      "sens and spec is:\n",
      "0.9623287671232876 0.6430379746835443\n",
      "517/517 [==============================] - 3s 6ms/step\n",
      "sensitivity, specificity and accuracy of models:\n",
      "0.8454883351255319\n",
      "0.8278736734432937\n",
      "0.835346518420754\n",
      "[[142 119]\n",
      " [ 48 208]]\n",
      "sensitivity, specificity and accuracy of subject:\n",
      "0.8125\n",
      "0.5440613026819924\n",
      "0.6769826030592854\n"
     ]
    }
   ],
   "source": [
    "sens_l = []\n",
    "spec_l = []\n",
    "acc_l = []\n",
    "\n",
    "data_training = np.concatenate((data_sub_2, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "    y_pred = model.predict(data_test, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    sens_l.append(sens)\n",
    "    spec = tn/(tn+fp)\n",
    "    spec_l.append(spec)\n",
    "    acc_l.append(acc)\n",
    "    print(confusion_matrix(labels_test,y_pred))\n",
    "    print(\"sens and spec is:\")\n",
    "    print(sens, spec)\n",
    "    \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_1, y=labels_sub_1, batch_size=5, verbose=1)\n",
    "    y_pred = model.predict(data_sub_1, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_sub_1,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    print(\"sensitivity, specificity and accuracy of models:\")\n",
    "    print(np.mean(sens_l))\n",
    "    print(np.mean(spec_l))\n",
    "    print(np.mean(acc_l))\n",
    "    print(confusion_matrix(labels_sub_1,y_pred))\n",
    "    print(\"sensitivity, specificity and accuracy of subject:\")\n",
    "    print(sens)\n",
    "    print(spec)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2749/2749 [==============================] - 33s 12ms/step - loss: 0.5856 - acc: 0.6475\n",
      "689/689 [==============================] - 5s 8ms/step\n",
      "0.5270439912450158 0.7024673518274623\n",
      "[[194 202]\n",
      " [  3 290]]\n",
      "sens and spec is:\n",
      "0.9897610921501706 0.4898989898989899\n",
      "Epoch 1/1\n",
      "2750/2750 [==============================] - 34s 12ms/step - loss: 0.5671 - acc: 0.6687\n",
      "688/688 [==============================] - 5s 8ms/step\n",
      "0.4465325037937958 0.7892441958795453\n",
      "[[287 108]\n",
      " [ 37 256]]\n",
      "sens and spec is:\n",
      "0.8737201365187713 0.7265822784810126\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 35s 13ms/step - loss: 0.5425 - acc: 0.6867\n",
      "687/687 [==============================] - 5s 8ms/step\n",
      "0.42435905454596273 0.7918486247243145\n",
      "[[265 130]\n",
      " [ 13 279]]\n",
      "sens and spec is:\n",
      "0.9554794520547946 0.6708860759493671\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 36s 13ms/step - loss: 0.5844 - acc: 0.6587\n",
      "687/687 [==============================] - 6s 9ms/step\n",
      "0.4674602402252141 0.7554585248925973\n",
      "[[309  86]\n",
      " [ 82 210]]\n",
      "sens and spec is:\n",
      "0.7191780821917808 0.7822784810126582\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 36s 13ms/step - loss: 0.6195 - acc: 0.6107\n",
      "687/687 [==============================] - 6s 8ms/step\n",
      "0.5293127962291848 0.7176128205080047\n",
      "[[255 140]\n",
      " [ 54 238]]\n",
      "sens and spec is:\n",
      "0.815068493150685 0.6455696202531646\n",
      "517/517 [==============================] - 3s 6ms/step\n",
      "sensitivity, specificity and accuracy of models:\n",
      "0.8706414512132404\n",
      "0.6630430891190384\n",
      "0.7513263035663849\n",
      "[[154 107]\n",
      " [ 80 176]]\n",
      "sensitivity, specificity and accuracy of subject:\n",
      "0.6875\n",
      "0.5900383141762452\n",
      "0.6382978857140016\n"
     ]
    }
   ],
   "source": [
    "sens_l = []\n",
    "spec_l = []\n",
    "acc_l = []\n",
    "\n",
    "data_training = np.concatenate((data_sub_2, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "    y_pred = model.predict(data_test, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    sens_l.append(sens)\n",
    "    spec = tn/(tn+fp)\n",
    "    spec_l.append(spec)\n",
    "    acc_l.append(acc)\n",
    "    print(confusion_matrix(labels_test,y_pred))\n",
    "    print(\"sens and spec is:\")\n",
    "    print(sens, spec)\n",
    "    \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_1, y=labels_sub_1, batch_size=5, verbose=1)\n",
    "    y_pred = model.predict(data_sub_1, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_sub_1,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    print(\"sensitivity, specificity and accuracy of models:\")\n",
    "    print(np.mean(sens_l))\n",
    "    print(np.mean(spec_l))\n",
    "    print(np.mean(acc_l))\n",
    "    print(confusion_matrix(labels_sub_1,y_pred))\n",
    "    print(\"sensitivity, specificity and accuracy of subject:\")\n",
    "    print(sens)\n",
    "    print(spec)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2749/2749 [==============================] - 35s 13ms/step - loss: 0.6162 - acc: 0.6231\n",
      "689/689 [==============================] - 6s 8ms/step\n",
      "0.49079634978048 0.7460087177888403\n",
      "[[301  95]\n",
      " [ 80 213]]\n",
      "sens and spec is:\n",
      "0.726962457337884 0.76010101010101\n",
      "Epoch 1/1\n",
      "2750/2750 [==============================] - 36s 13ms/step - loss: 0.5855 - acc: 0.6360\n",
      "688/688 [==============================] - 6s 9ms/step\n",
      "0.5000594366060267 0.7601744271598236\n",
      "[[295 100]\n",
      " [ 65 228]]\n",
      "sens and spec is:\n",
      "0.7781569965870307 0.7468354430379747\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 37s 13ms/step - loss: 0.6005 - acc: 0.6416\n",
      "687/687 [==============================] - 6s 9ms/step\n",
      "0.5190336027411742 0.7321688587705468\n",
      "[[226 169]\n",
      " [ 15 277]]\n",
      "sens and spec is:\n",
      "0.9486301369863014 0.5721518987341773\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 37s 13ms/step - loss: 0.6496 - acc: 0.5885\n",
      "687/687 [==============================] - 6s 9ms/step\n",
      "0.5364214138031613 0.7103347969844699\n",
      "[[209 186]\n",
      " [ 13 279]]\n",
      "sens and spec is:\n",
      "0.9554794520547946 0.529113924050633\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 37s 13ms/step - loss: 0.6326 - acc: 0.5936\n",
      "687/687 [==============================] - 6s 9ms/step\n",
      "0.5359583060396768 0.6943231535834169\n",
      "[[212 183]\n",
      " [ 27 265]]\n",
      "sens and spec is:\n",
      "0.9075342465753424 0.5367088607594936\n",
      "517/517 [==============================] - 3s 6ms/step\n",
      "sensitivity, specificity and accuracy of models:\n",
      "0.8633526579082705\n",
      "0.6289822273366577\n",
      "0.7286019908574195\n",
      "[[139 122]\n",
      " [ 80 176]]\n",
      "sensitivity, specificity and accuracy of subject:\n",
      "0.6875\n",
      "0.5325670498084292\n",
      "0.6092843447651577\n"
     ]
    }
   ],
   "source": [
    "sens_l = []\n",
    "spec_l = []\n",
    "acc_l = []\n",
    "\n",
    "data_training = np.concatenate((data_sub_2, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "    y_pred = model.predict(data_test, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    sens_l.append(sens)\n",
    "    spec = tn/(tn+fp)\n",
    "    spec_l.append(spec)\n",
    "    acc_l.append(acc)\n",
    "    print(confusion_matrix(labels_test,y_pred))\n",
    "    print(\"sens and spec is:\")\n",
    "    print(sens, spec)\n",
    "    \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_1, y=labels_sub_1, batch_size=5, verbose=1)\n",
    "    y_pred = model.predict(data_sub_1, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_sub_1,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    print(\"sensitivity, specificity and accuracy of models:\")\n",
    "    print(np.mean(sens_l))\n",
    "    print(np.mean(spec_l))\n",
    "    print(np.mean(acc_l))\n",
    "    print(confusion_matrix(labels_sub_1,y_pred))\n",
    "    print(\"sensitivity, specificity and accuracy of subject:\")\n",
    "    print(sens)\n",
    "    print(spec)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 2 as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 37s 13ms/step - loss: 0.4763 - acc: 0.7636\n",
      "720/720 [==============================] - 3s 4ms/step\n",
      "0.2466100368506482 0.9152777812754115\n",
      "[[402  10]\n",
      " [ 51 257]]\n",
      "sens and spec is:\n",
      "0.8344155844155844 0.9757281553398058\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 37s 13ms/step - loss: 0.4498 - acc: 0.7762\n",
      "720/720 [==============================] - 3s 4ms/step\n",
      "0.16673402197759263 0.9319444482939111\n",
      "[[381  31]\n",
      " [ 18 290]]\n",
      "sens and spec is:\n",
      "0.9415584415584416 0.9247572815533981\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 37s 13ms/step - loss: 0.4388 - acc: 0.7855\n",
      "720/720 [==============================] - 3s 5ms/step\n",
      "0.29524221702983294 0.8791666720062494\n",
      "[[329  83]\n",
      " [  4 304]]\n",
      "sens and spec is:\n",
      "0.987012987012987 0.7985436893203883\n",
      "Epoch 1/1\n",
      "2878/2878 [==============================] - 38s 13ms/step - loss: 0.4083 - acc: 0.8030\n",
      "719/719 [==============================] - 3s 5ms/step\n",
      "0.2068038180642742 0.9221140500650287\n",
      "[[404   7]\n",
      " [ 49 259]]\n",
      "sens and spec is:\n",
      "0.8409090909090909 0.9829683698296837\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 38s 13ms/step - loss: 0.4398 - acc: 0.7906\n",
      "718/718 [==============================] - 3s 5ms/step\n",
      "0.22927629049415998 0.9011142103618898\n",
      "[[397  14]\n",
      " [ 57 250]]\n",
      "sens and spec is:\n",
      "0.8143322475570033 0.9659367396593674\n",
      "358/358 [==============================] - 2s 4ms/step\n",
      "sensitivity, specificity and accuracy of models:\n",
      "0.8836456702906215\n",
      "0.9295868471405286\n",
      "0.909923432400498\n",
      "[[172   7]\n",
      " [114  65]]\n",
      "sensitivity, specificity and accuracy of subject:\n",
      "0.36312849162011174\n",
      "0.9608938547486033\n",
      "0.6620111781375368\n"
     ]
    }
   ],
   "source": [
    "sens_l = []\n",
    "spec_l = []\n",
    "acc_l = []\n",
    "\n",
    "data_training = np.concatenate((data_sub_1, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_1, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "    y_pred = model.predict(data_test, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    sens_l.append(sens)\n",
    "    spec = tn/(tn+fp)\n",
    "    spec_l.append(spec)\n",
    "    acc_l.append(acc)\n",
    "    print(confusion_matrix(labels_test,y_pred))\n",
    "    print(\"sens and spec is:\")\n",
    "    print(sens, spec)\n",
    "    \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_2, y=labels_sub_2, batch_size=5, verbose=1)\n",
    "    y_pred = model.predict(data_sub_2, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_sub_2,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    print(\"sensitivity, specificity and accuracy of models:\")\n",
    "    print(np.mean(sens_l))\n",
    "    print(np.mean(spec_l))\n",
    "    print(np.mean(acc_l))\n",
    "    print(confusion_matrix(labels_sub_2,y_pred))\n",
    "    print(\"sensitivity, specificity and accuracy of subject:\")\n",
    "    print(sens)\n",
    "    print(spec)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 34s 12ms/step - loss: 0.5237 - acc: 0.6927\n",
      "720/720 [==============================] - 4s 6ms/step\n",
      "0.3499336114424902 0.8305555632751849\n",
      "[[358  54]\n",
      " [ 68 240]]\n",
      "sens and spec is:\n",
      "0.7792207792207793 0.8689320388349514\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 34s 12ms/step - loss: 0.5083 - acc: 0.7157\n",
      "720/720 [==============================] - 4s 6ms/step\n",
      "0.3441493534976164 0.8555555621989899\n",
      "[[335  77]\n",
      " [ 27 281]]\n",
      "sens and spec is:\n",
      "0.9123376623376623 0.8131067961165048\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 34s 12ms/step - loss: 0.5089 - acc: 0.7105\n",
      "720/720 [==============================] - 4s 6ms/step\n",
      "0.4362986243924954 0.8013888978295856\n",
      "[[372  40]\n",
      " [103 205]]\n",
      "sens and spec is:\n",
      "0.6655844155844156 0.9029126213592233\n",
      "Epoch 1/1\n",
      "2878/2878 [==============================] - 34s 12ms/step - loss: 0.5488 - acc: 0.6703\n",
      "719/719 [==============================] - 4s 6ms/step\n",
      "0.4496108311926622 0.7538247663263485\n",
      "[[260 151]\n",
      " [ 26 282]]\n",
      "sens and spec is:\n",
      "0.9155844155844156 0.6326034063260341\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 35s 12ms/step - loss: 0.5196 - acc: 0.7127\n",
      "718/718 [==============================] - 4s 6ms/step\n",
      "0.3786539401477047 0.8300835725573776\n",
      "[[354  57]\n",
      " [ 65 242]]\n",
      "sens and spec is:\n",
      "0.7882736156351792 0.8613138686131386\n",
      "358/358 [==============================] - 2s 6ms/step\n",
      "sensitivity, specificity and accuracy of models:\n",
      "0.8122001776724904\n",
      "0.8157737462499706\n",
      "0.8142816724374974\n",
      "[[164  15]\n",
      " [ 70 109]]\n",
      "sensitivity, specificity and accuracy of subject:\n",
      "0.6089385474860335\n",
      "0.9162011173184358\n",
      "0.7625698421837231\n"
     ]
    }
   ],
   "source": [
    "sens_l = []\n",
    "spec_l = []\n",
    "acc_l = []\n",
    "\n",
    "data_training = np.concatenate((data_sub_1, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_1, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "    y_pred = model.predict(data_test, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    sens_l.append(sens)\n",
    "    spec = tn/(tn+fp)\n",
    "    spec_l.append(spec)\n",
    "    acc_l.append(acc)\n",
    "    print(confusion_matrix(labels_test,y_pred))\n",
    "    print(\"sens and spec is:\")\n",
    "    print(sens, spec)\n",
    "    \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_2, y=labels_sub_2, batch_size=5, verbose=1)\n",
    "    y_pred = model.predict(data_sub_2, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_sub_2,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    print(\"sensitivity, specificity and accuracy of models:\")\n",
    "    print(np.mean(sens_l))\n",
    "    print(np.mean(spec_l))\n",
    "    print(np.mean(acc_l))\n",
    "    print(confusion_matrix(labels_sub_2,y_pred))\n",
    "    print(\"sensitivity, specificity and accuracy of subject:\")\n",
    "    print(sens)\n",
    "    print(spec)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 34s 12ms/step - loss: 0.5888 - acc: 0.6482\n",
      "720/720 [==============================] - 5s 6ms/step\n",
      "0.5179859543374429 0.7125000074091885\n",
      "[[361  51]\n",
      " [156 152]]\n",
      "sens and spec is:\n",
      "0.4935064935064935 0.8762135922330098\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 35s 12ms/step - loss: 0.5473 - acc: 0.6802\n",
      "720/720 [==============================] - 5s 7ms/step\n",
      "0.40687322154796374 0.8166666746967368\n",
      "[[284 128]\n",
      " [  4 304]]\n",
      "sens and spec is:\n",
      "0.987012987012987 0.6893203883495146\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 35s 12ms/step - loss: 0.5554 - acc: 0.6788\n",
      "720/720 [==============================] - 5s 7ms/step\n",
      "0.5085385063171594 0.7250000111137828\n",
      "[[327  85]\n",
      " [113 195]]\n",
      "sens and spec is:\n",
      "0.6331168831168831 0.7936893203883495\n",
      "Epoch 1/1\n",
      "2878/2878 [==============================] - 36s 12ms/step - loss: 0.5887 - acc: 0.6508\n",
      "719/719 [==============================] - 5s 7ms/step\n",
      "0.5151722642731683 0.7677329704890828\n",
      "[[363  48]\n",
      " [119 189]]\n",
      "sens and spec is:\n",
      "0.6136363636363636 0.8832116788321168\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 36s 13ms/step - loss: 0.5680 - acc: 0.6683\n",
      "718/718 [==============================] - 5s 7ms/step\n",
      "0.49965518850864893 0.7130919290410775\n",
      "[[380  31]\n",
      " [175 132]]\n",
      "sens and spec is:\n",
      "0.42996742671009774 0.9245742092457421\n",
      "358/358 [==============================] - 2s 6ms/step\n",
      "sensitivity, specificity and accuracy of models:\n",
      "0.6314480307965651\n",
      "0.8334018378097466\n",
      "0.7469983185499738\n",
      "[[156  23]\n",
      " [ 55 124]]\n",
      "sensitivity, specificity and accuracy of subject:\n",
      "0.6927374301675978\n",
      "0.8715083798882681\n",
      "0.7821229142683178\n"
     ]
    }
   ],
   "source": [
    "sens_l = []\n",
    "spec_l = []\n",
    "acc_l = []\n",
    "\n",
    "data_training = np.concatenate((data_sub_1, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_1, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "    y_pred = model.predict(data_test, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    sens_l.append(sens)\n",
    "    spec = tn/(tn+fp)\n",
    "    spec_l.append(spec)\n",
    "    acc_l.append(acc)\n",
    "    print(confusion_matrix(labels_test,y_pred))\n",
    "    print(\"sens and spec is:\")\n",
    "    print(sens, spec)\n",
    "    \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_2, y=labels_sub_2, batch_size=5, verbose=1)\n",
    "    y_pred = model.predict(data_sub_2, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_sub_2,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    print(\"sensitivity, specificity and accuracy of models:\")\n",
    "    print(np.mean(sens_l))\n",
    "    print(np.mean(spec_l))\n",
    "    print(np.mean(acc_l))\n",
    "    print(confusion_matrix(labels_sub_2,y_pred))\n",
    "    print(\"sensitivity, specificity and accuracy of subject:\")\n",
    "    print(sens)\n",
    "    print(spec)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 35s 12ms/step - loss: 0.6097 - acc: 0.6170\n",
      "720/720 [==============================] - 5s 7ms/step\n",
      "0.5750315971672535 0.6500000077196293\n",
      "[[183 229]\n",
      " [ 23 285]]\n",
      "sens and spec is:\n",
      "0.9253246753246753 0.4441747572815534\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 36s 12ms/step - loss: 0.5820 - acc: 0.6555\n",
      "720/720 [==============================] - 5s 7ms/step\n",
      "0.630590307008889 0.5944444488527046\n",
      "[[120 292]\n",
      " [  0 308]]\n",
      "sens and spec is:\n",
      "1.0 0.2912621359223301\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 37s 13ms/step - loss: 0.6126 - acc: 0.6291\n",
      "720/720 [==============================] - 5s 7ms/step\n",
      "0.543579533799655 0.6666666762903333\n",
      "[[232 180]\n",
      " [ 60 248]]\n",
      "sens and spec is:\n",
      "0.8051948051948052 0.5631067961165048\n",
      "Epoch 1/1\n",
      "2878/2878 [==============================] - 38s 13ms/step - loss: 0.6380 - acc: 0.6077\n",
      "719/719 [==============================] - 5s 8ms/step\n",
      "0.510307967704261 0.7649513308751567\n",
      "[[317  94]\n",
      " [ 75 233]]\n",
      "sens and spec is:\n",
      "0.7564935064935064 0.7712895377128953\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 38s 13ms/step - loss: 0.6303 - acc: 0.5999\n",
      "718/718 [==============================] - 6s 8ms/step\n",
      "0.5570936507563571 0.6559888642270917\n",
      "[[369  42]\n",
      " [205 102]]\n",
      "sens and spec is:\n",
      "0.3322475570032573 0.8978102189781022\n",
      "358/358 [==============================] - 2s 6ms/step\n",
      "sensitivity, specificity and accuracy of models:\n",
      "0.7638521088032488\n",
      "0.5935286892022772\n",
      "0.6664102655929831\n",
      "[[142  37]\n",
      " [ 80  99]]\n",
      "sensitivity, specificity and accuracy of subject:\n",
      "0.553072625698324\n",
      "0.7932960893854749\n",
      "0.6731843691131922\n"
     ]
    }
   ],
   "source": [
    "sens_l = []\n",
    "spec_l = []\n",
    "acc_l = []\n",
    "\n",
    "data_training = np.concatenate((data_sub_1, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_1, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "    y_pred = model.predict(data_test, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_test,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    sens_l.append(sens)\n",
    "    spec = tn/(tn+fp)\n",
    "    spec_l.append(spec)\n",
    "    acc_l.append(acc)\n",
    "    print(confusion_matrix(labels_test,y_pred))\n",
    "    print(\"sens and spec is:\")\n",
    "    print(sens, spec)\n",
    "    \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_2, y=labels_sub_2, batch_size=5, verbose=1)\n",
    "    y_pred = model.predict(data_sub_2, verbose=0)\n",
    "    y_pred = y_pred.round()\n",
    "    y_pred = np.array([int(i) for i in y_pred])\n",
    "    tn, fp, fn, tp = confusion_matrix(labels_sub_2,y_pred).ravel()\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    print(\"sensitivity, specificity and accuracy of models:\")\n",
    "    print(np.mean(sens_l))\n",
    "    print(np.mean(spec_l))\n",
    "    print(np.mean(acc_l))\n",
    "    print(confusion_matrix(labels_sub_2,y_pred))\n",
    "    print(\"sensitivity, specificity and accuracy of subject:\")\n",
    "    print(sens)\n",
    "    print(spec)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layers - subject 2 as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3597/3597 [==============================] - 132s 37ms/step - loss: 9.1213 - acc: 0.4279\n",
      "Epoch 2/2\n",
      "3597/3597 [==============================] - 90s 25ms/step - loss: 9.1213 - acc: 0.4279\n",
      "358/358 [==============================] - 5s 15ms/step\n",
      "7.971192417864046 0.49999999933402633\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_1, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_1, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 30, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 15, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=20, epochs=2,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_sub_2, y=labels_sub_2, batch_size=20, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 39s 14ms/step - loss: 0.4437 - acc: 0.7786\n",
      "720/720 [==============================] - 5s 6ms/step\n",
      "0.23498108607681287 0.9194444473832846\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 39s 14ms/step - loss: 0.4589 - acc: 0.7664\n",
      "720/720 [==============================] - 5s 7ms/step\n",
      "0.3098798149989711 0.8736111164713899\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 40s 14ms/step - loss: 0.4721 - acc: 0.7550\n",
      "720/720 [==============================] - 5s 7ms/step\n",
      "0.19984528016518904 0.9194444492459297\n",
      "Epoch 1/1\n",
      "2878/2878 [==============================] - 40s 14ms/step - loss: 0.4481 - acc: 0.7755\n",
      "719/719 [==============================] - 5s 7ms/step\n",
      "0.23456822238054245 0.8901251790545083\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 40s 14ms/step - loss: 0.4863 - acc: 0.7600\n",
      "718/718 [==============================] - 5s 7ms/step\n",
      "0.2427278352955818 0.8983286960377335\n",
      "358/358 [==============================] - 2s 4ms/step\n",
      "0.36065692262588767 0.8463687229922364\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_1, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_1, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10), axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_2, y=labels_sub_2, batch_size=5, verbose=1)\n",
    "\n",
    "    print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 38s 13ms/step - loss: 0.5277 - acc: 0.6931\n",
      "720/720 [==============================] - 6s 9ms/step\n",
      "0.42704053688794374 0.8222222296107147\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 39s 14ms/step - loss: 0.5133 - acc: 0.6993\n",
      "720/720 [==============================] - 6s 9ms/step\n",
      "0.4347013759478513 0.7833333417980207\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 41s 14ms/step - loss: 0.5617 - acc: 0.6761\n",
      "720/720 [==============================] - 7s 9ms/step\n",
      "0.45845804860841277 0.7472222277687656\n",
      "Epoch 1/1\n",
      "2878/2878 [==============================] - 41s 14ms/step - loss: 0.5339 - acc: 0.6821\n",
      "719/719 [==============================] - 7s 9ms/step\n",
      "0.3964750896258505 0.7844228174780937\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 40s 14ms/step - loss: 0.5050 - acc: 0.6989\n",
      "718/718 [==============================] - 7s 9ms/step\n",
      "0.38233953352023986 0.7896936025086552\n",
      "358/358 [==============================] - 2s 5ms/step\n",
      "0.470865279852345 0.6955307282549043\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_1, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_1, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10), axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_2, y=labels_sub_2, batch_size=10, verbose=1)\n",
    "\n",
    "    print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 38s 13ms/step - loss: 0.6273 - acc: 0.6361\n",
      "720/720 [==============================] - 6s 8ms/step\n",
      "0.5645190679157773 0.6361111137602065\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 40s 14ms/step - loss: 0.6034 - acc: 0.6263\n",
      "720/720 [==============================] - 7s 10ms/step\n",
      "0.5486681829206645 0.6805555655931433\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 42s 14ms/step - loss: 0.6586 - acc: 0.5954\n",
      "720/720 [==============================] - 6s 9ms/step\n",
      "0.527298195546286 0.651388892903924\n",
      "Epoch 1/1\n",
      "2878/2878 [==============================] - 39s 14ms/step - loss: 0.6270 - acc: 0.6286\n",
      "719/719 [==============================] - 6s 9ms/step\n",
      "0.4594330576757521 0.7538247669688186\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 39s 14ms/step - loss: 0.5831 - acc: 0.6641\n",
      "718/718 [==============================] - 6s 9ms/step\n",
      "0.4895921841881194 0.7075209014304501\n",
      "358/358 [==============================] - 2s 6ms/step\n",
      "0.453517316132992 0.8212290601024415\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_1, data_sub_3, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_1, labels_sub_3, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10), axis = 0)\n",
    "\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_2, y=labels_sub_2, batch_size=5, verbose=1)\n",
    "\n",
    "    print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 3 as test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3502/3502 [==============================] - 53s 15ms/step - loss: 9.1457 - acc: 0.4263\n",
      "453/453 [==============================] - 5s 11ms/step\n",
      "8.023981778826956 0.4966887417218543\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "  \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=1,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_sub_3, y=labels_sub_3, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 44s 16ms/step - loss: 0.4054 - acc: 0.8061\n",
      "701/701 [==============================] - 7s 9ms/step\n",
      "0.16043702084086198 0.9229671937890468\n",
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 43s 15ms/step - loss: 0.4743 - acc: 0.7658\n",
      "701/701 [==============================] - 7s 10ms/step\n",
      "0.22844308203274913 0.9358059950544899\n",
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 43s 15ms/step - loss: 0.4357 - acc: 0.7861\n",
      "701/701 [==============================] - 7s 10ms/step\n",
      "0.18650562736835496 0.9300998598124604\n",
      "Epoch 1/1\n",
      "2802/2802 [==============================] - 44s 16ms/step - loss: 0.4281 - acc: 0.7959\n",
      "700/700 [==============================] - 7s 10ms/step\n",
      "0.27219909891220073 0.8614285778786455\n",
      "Epoch 1/1\n",
      "2803/2803 [==============================] - 44s 16ms/step - loss: 0.4381 - acc: 0.7927\n",
      "699/699 [==============================] - 7s 10ms/step\n",
      "0.20069729632701996 0.9113018648733567\n",
      "453/453 [==============================] - 2s 5ms/step\n",
      "0.9468950280512602 0.5871964749976762\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_3, y=labels_sub_3, batch_size=5, verbose=1)\n",
    "\n",
    "    print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 layers and subject 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4183/4183 [==============================] - 46s 11ms/step - loss: 9.0288 - acc: 0.4337\n",
      "Epoch 2/3\n",
      "4183/4183 [==============================] - 44s 10ms/step - loss: 9.0288 - acc: 0.4337\n",
      "Epoch 3/3\n",
      "4183/4183 [==============================] - 44s 11ms/step - loss: 9.0288 - acc: 0.4337\n",
      "906/906 [==============================] - 5s 6ms/step\n",
      "8.023981777116436 0.4966887418863263\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_3))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_3, data_sub_3)) \n",
    "    labels_test = np.concatenate((labels_sub_3, labels_sub_3))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=3,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 49s 17ms/step - loss: 0.5325 - acc: 0.7019\n",
      "701/701 [==============================] - 8s 11ms/step\n",
      "0.44941455995751683 0.8687589215313997\n",
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 41s 15ms/step - loss: 0.5292 - acc: 0.7122\n",
      "701/701 [==============================] - 8s 12ms/step\n",
      "0.4438470402883948 0.8031383828285247\n",
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 43s 15ms/step - loss: 0.5688 - acc: 0.6694\n",
      "701/701 [==============================] - 8s 12ms/step\n",
      "0.4653443654468708 0.748930111654985\n",
      "Epoch 1/1\n",
      "2802/2802 [==============================] - 43s 15ms/step - loss: 0.5849 - acc: 0.6709\n",
      "700/700 [==============================] - 8s 12ms/step\n",
      "0.5021579936080213 0.6700000034911292\n",
      "Epoch 1/1\n",
      "2803/2803 [==============================] - 44s 16ms/step - loss: 0.5326 - acc: 0.7071\n",
      "699/699 [==============================] - 9s 12ms/step\n",
      "0.43321258897547715 0.7839771181302351\n",
      "453/453 [==============================] - 3s 6ms/step\n",
      "0.7692995113387465 0.5584988998656242\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_3, y=labels_sub_3, batch_size=5, verbose=1)\n",
    "\n",
    "    print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 43s 15ms/step - loss: 0.6003 - acc: 0.6266\n",
      "701/701 [==============================] - 9s 13ms/step\n",
      "0.5326136752495412 0.7389443751408609\n",
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 43s 15ms/step - loss: 0.6360 - acc: 0.5941\n",
      "701/701 [==============================] - 9s 13ms/step\n",
      "0.5448640272042551 0.6376604902506214\n",
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 43s 15ms/step - loss: 0.5990 - acc: 0.6473\n",
      "701/701 [==============================] - 9s 13ms/step\n",
      "0.5491505335756018 0.6205420875005137\n",
      "Epoch 1/1\n",
      "2802/2802 [==============================] - 44s 16ms/step - loss: 0.6006 - acc: 0.6395\n",
      "700/700 [==============================] - 9s 13ms/step\n",
      "0.574284538520234 0.6828571518617017\n",
      "Epoch 1/1\n",
      "2803/2803 [==============================] - 44s 16ms/step - loss: 0.6555 - acc: 0.5929\n",
      "699/699 [==============================] - 9s 13ms/step\n",
      "0.5682353702225911 0.6952789801256851\n",
      "453/453 [==============================] - 3s 6ms/step\n",
      "0.6017461236870578 0.596026496710893\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_3, y=labels_sub_3, batch_size=5, verbose=1)\n",
    "\n",
    "    print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 45s 16ms/step - loss: 0.6921 - acc: 0.5566\n",
      "701/701 [==============================] - 10s 14ms/step\n",
      "0.6834178019352204 0.5734664776525892\n",
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 45s 16ms/step - loss: 0.6749 - acc: 0.5552\n",
      "701/701 [==============================] - 10s 14ms/step\n",
      "0.6585237723529423 0.573466477227449\n",
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 45s 16ms/step - loss: 0.6737 - acc: 0.5780\n",
      "701/701 [==============================] - 10s 14ms/step\n",
      "0.6775578774841298 0.5734664773337341\n",
      "Epoch 1/1\n",
      "2802/2802 [==============================] - 46s 16ms/step - loss: 0.6669 - acc: 0.5735\n",
      "700/700 [==============================] - 11s 16ms/step\n",
      "0.6679660648107528 0.5714285723865032\n",
      "Epoch 1/1\n",
      "2803/2803 [==============================] - 47s 17ms/step - loss: 0.6884 - acc: 0.5540\n",
      "699/699 [==============================] - 10s 15ms/step\n",
      "0.6828562187534545 0.5736766819747562\n",
      "453/453 [==============================] - 3s 6ms/step\n",
      "0.7075360919992392 0.5033112582781457\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_3, y=labels_sub_3, batch_size=5, verbose=1)\n",
    "\n",
    "    print(loss, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4334/4334 [==============================] - 49s 11ms/step - loss: 8.4420 - acc: 0.4705\n",
      "Epoch 2/3\n",
      "4334/4334 [==============================] - 47s 11ms/step - loss: 8.4420 - acc: 0.4705\n",
      "Epoch 3/3\n",
      "4334/4334 [==============================] - 48s 11ms/step - loss: 8.4420 - acc: 0.4705\n",
      "604/604 [==============================] - 4s 7ms/step\n",
      "15.942384719848633 0.0\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_4))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.array([data_sub_4,], limit)\n",
    "    labels_test = np.array([labels_sub_4,], limit)\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=3,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 55s 19ms/step - loss: 0.4494 - acc: 0.7765\n",
      "731/731 [==============================] - 10s 13ms/step\n",
      "0.22487623746176894 0.9110807162466192\n",
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 55s 19ms/step - loss: 0.4897 - acc: 0.7529\n",
      "731/731 [==============================] - 10s 14ms/step\n",
      "0.22624518324665346 0.9042407711700278\n",
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 52s 18ms/step - loss: 0.4380 - acc: 0.7752\n",
      "731/731 [==============================] - 10s 14ms/step\n",
      "0.28448650558070165 0.8837209348190989\n",
      "Epoch 1/1\n",
      "2923/2923 [==============================] - 61s 21ms/step - loss: 0.4976 - acc: 0.7458\n",
      "730/730 [==============================] - 10s 14ms/step\n",
      "0.2699483315355132 0.8931506895651556\n",
      "Epoch 1/1\n",
      "2923/2923 [==============================] - 53s 18ms/step - loss: 0.4192 - acc: 0.7951\n",
      "730/730 [==============================] - 11s 14ms/step\n",
      "0.19516684742329868 0.9219178126691139\n",
      "302/302 [==============================] - 2s 5ms/step\n",
      "0.3111865697120199 0.8708609343561905\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_4, y=labels_sub_4, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "    y_pred = model.predict(data_sub_4, verbose=0)\n",
    "    y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion_matrix(labels_sub_4,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4334/4334 [==============================] - 50s 11ms/step - loss: 8.4420 - acc: 0.4705\n",
      "Epoch 2/3\n",
      "4334/4334 [==============================] - 48s 11ms/step - loss: 8.4420 - acc: 0.4705\n",
      "Epoch 3/3\n",
      "4334/4334 [==============================] - 51s 12ms/step - loss: 8.4420 - acc: 0.4705\n",
      "604/604 [==============================] - 4s 7ms/step\n",
      "15.942384719848633 0.0\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_4))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_4, data_sub_4)) \n",
    "    labels_test = np.concatenate((labels_sub_4, labels_sub_4))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=3,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_sub_4, y=labels_sub_4, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 53s 18ms/step - loss: 0.5834 - acc: 0.6605\n",
      "731/731 [==============================] - 11s 15ms/step\n",
      "0.5235446862692954 0.7346101318028655\n",
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 51s 18ms/step - loss: 0.6049 - acc: 0.6550\n",
      "731/731 [==============================] - 11s 15ms/step\n",
      "0.47563557553827435 0.7619699114161542\n",
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 54s 18ms/step - loss: 0.5570 - acc: 0.6804\n",
      "731/731 [==============================] - 12s 16ms/step\n",
      "0.521079785785499 0.7647058919133305\n",
      "Epoch 1/1\n",
      "2923/2923 [==============================] - 53s 18ms/step - loss: 0.5444 - acc: 0.6842\n",
      "730/730 [==============================] - 12s 16ms/step\n",
      "0.49782890881162956 0.683561650245157\n",
      "Epoch 1/1\n",
      "2923/2923 [==============================] - 54s 18ms/step - loss: 0.5528 - acc: 0.6907\n",
      "730/730 [==============================] - 12s 16ms/step\n",
      "0.505446560782929 0.789041105402659\n",
      "302/302 [==============================] - 2s 6ms/step\n",
      "0.386889719694162 0.7086092822303046\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_4, y=labels_sub_4, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "    y_pred = model.predict(data_sub_4, verbose=0)\n",
    "    y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion_matrix(labels_sub_4,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[214,  88],\n",
       "       [  0,   0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(data_sub_4, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(labels_sub_4,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 54s 18ms/step - loss: 0.6183 - acc: 0.6287\n",
      "731/731 [==============================] - 12s 17ms/step\n",
      "0.5844429868149855 0.6867305145544165\n",
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 54s 18ms/step - loss: 0.6690 - acc: 0.5931\n",
      "731/731 [==============================] - 12s 17ms/step\n",
      "0.6712380012066681 0.5458276342554719\n",
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 54s 19ms/step - loss: 0.6776 - acc: 0.5975\n",
      "731/731 [==============================] - 13s 17ms/step\n",
      "0.7445494609231336 0.5294117659493445\n",
      "Epoch 1/1\n",
      "2923/2923 [==============================] - 55s 19ms/step - loss: 0.6775 - acc: 0.5737\n",
      "730/730 [==============================] - 13s 17ms/step\n",
      "0.6209113312094179 0.6000000046540613\n",
      "Epoch 1/1\n",
      "2923/2923 [==============================] - 55s 19ms/step - loss: 0.6598 - acc: 0.5706\n",
      "730/730 [==============================] - 13s 17ms/step\n",
      "0.6001752363900615 0.7178082283433169\n",
      "302/302 [==============================] - 2s 7ms/step\n",
      "0.5102799287102869 0.6324503451388404\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_4, y=labels_sub_4, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "    y_pred = model.predict(data_sub_4, verbose=0)\n",
    "    y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "    confusion_matrix(labels_sub_4,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_3,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_3, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_5))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_5, data_sub_5)) \n",
    "    labels_test = np.concatenate((labels_sub_5, labels_sub_5))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=1,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2781/2781 [==============================] - 55s 20ms/step - loss: 0.4427 - acc: 0.7886\n",
      "696/696 [==============================] - 12s 17ms/step\n",
      "0.1545460498562262 0.9554597722345043\n",
      "Epoch 1/1\n",
      "2781/2781 [==============================] - 56s 20ms/step - loss: 0.4389 - acc: 0.7929\n",
      "696/696 [==============================] - 12s 17ms/step\n",
      "0.22372629161222957 0.9022988558843218\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 56s 20ms/step - loss: 0.4893 - acc: 0.7631\n",
      "695/695 [==============================] - 12s 18ms/step\n",
      "0.2152846124184003 0.919424464162305\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 56s 20ms/step - loss: 0.4866 - acc: 0.7566\n",
      "695/695 [==============================] - 12s 18ms/step\n",
      "0.20593292792763213 0.9194244652343311\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 57s 20ms/step - loss: 0.4569 - acc: 0.7703\n",
      "695/695 [==============================] - 12s 18ms/step\n",
      "0.16663728750699447 0.9309352553791279\n",
      "478/478 [==============================] - 3s 6ms/step\n",
      "1.0490362716489958 0.5899581623937794\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_5, y=labels_sub_5, batch_size=5, verbose=1)\n",
    "    print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[225,  10],\n",
       "       [186,  57]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(data_sub_5, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_5,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-5ca1e344bacd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                   labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sub_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_3,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_3, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_5))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_5, data_sub_5)) \n",
    "    labels_test = np.concatenate((labels_sub_5, labels_sub_5))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=1,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2781/2781 [==============================] - 58s 21ms/step - loss: 0.5687 - acc: 0.6616\n",
      "696/696 [==============================] - 14s 20ms/step\n",
      "0.5313664184262356 0.7557471361996113\n",
      "Epoch 1/1\n",
      "2781/2781 [==============================] - 56s 20ms/step - loss: 0.5692 - acc: 0.6638\n",
      "696/696 [==============================] - 14s 20ms/step\n",
      "0.39928225697628383 0.850574718873905\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 57s 20ms/step - loss: 0.5594 - acc: 0.6797\n",
      "695/695 [==============================] - 14s 20ms/step\n",
      "0.4755306840813953 0.6920863348159859\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 57s 21ms/step - loss: 0.5431 - acc: 0.6873\n",
      "695/695 [==============================] - 14s 20ms/step\n",
      "0.49833015411448994 0.7597122370339126\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 57s 21ms/step - loss: 0.5334 - acc: 0.6937\n",
      "695/695 [==============================] - 14s 20ms/step\n",
      "0.431423962303846 0.8057554040452559\n",
      "478/478 [==============================] - 3s 7ms/step\n",
      "0.43955164000579006 0.8368200909143712\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_5, y=labels_sub_5, batch_size=5, verbose=1)\n",
    "    print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[172,  63],\n",
       "       [ 15, 228]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(data_sub_5, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_5,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2781/2781 [==============================] - 60s 22ms/step - loss: 0.6674 - acc: 0.5761\n",
      "696/696 [==============================] - 15s 21ms/step\n",
      "0.5567711929405301 0.6307471296054193\n",
      "Epoch 1/1\n",
      "2781/2781 [==============================] - 59s 21ms/step - loss: 0.6395 - acc: 0.5948\n",
      "696/696 [==============================] - 15s 21ms/step\n",
      "0.5577037953017293 0.642241390464806\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 59s 21ms/step - loss: 0.6593 - acc: 0.5766\n",
      "695/695 [==============================] - 15s 21ms/step\n",
      "0.6042864191875184 0.5755395692029446\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 61s 22ms/step - loss: 0.6634 - acc: 0.5899\n",
      "695/695 [==============================] - 15s 22ms/step\n",
      "0.6277015134156179 0.5755395690957419\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 61s 22ms/step - loss: 0.6790 - acc: 0.5651\n",
      "695/695 [==============================] - 15s 22ms/step\n",
      "0.6247443636115506 0.5755395692029446\n",
      "478/478 [==============================] - 3s 7ms/step\n",
      "0.601888292504155 0.49163179922552785\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_model()\n",
    "    kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "    for train, test in kFold.split(data_training,labels_training):\n",
    "        model = None\n",
    "        model = load_model()\n",
    "        train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "        \n",
    "    loss, acc = model.evaluate(x=data_sub_5, y=labels_sub_5, batch_size=5, verbose=1)\n",
    "    print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[235,   0],\n",
       "       [243,   0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(data_sub_5, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_5,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3460/3460 [==============================] - 70s 20ms/step - loss: 9.1461 - acc: 0.4263 \n",
      "990/990 [==============================] - 16s 16ms/step\n",
      "8.116123189829827 0.49090909114991776\n"
     ]
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_3, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_3, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "data_test = np.concatenate((data_sub_6, data_sub_6)) \n",
    "labels_test = np.concatenate((labels_sub_6, labels_sub_6))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=1,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 62s 22ms/step - loss: 0.4820 - acc: 0.7457\n",
      "692/692 [==============================] - 15s 21ms/step\n",
      "0.31704180719293223 0.8641618564078918\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 62s 22ms/step - loss: 0.4340 - acc: 0.7868\n",
      "692/692 [==============================] - 15s 21ms/step\n",
      "0.24930735081150782 0.9017341078792004\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 62s 22ms/step - loss: 0.4691 - acc: 0.7742\n",
      "692/692 [==============================] - 15s 21ms/step\n",
      "0.23345203719214896 0.9089595420296827\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 63s 23ms/step - loss: 0.4508 - acc: 0.7735\n",
      "692/692 [==============================] - 15s 22ms/step\n",
      "0.3216666115156504 0.8627167690351519\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 63s 23ms/step - loss: 0.5152 - acc: 0.7388\n",
      "692/692 [==============================] - 15s 22ms/step\n",
      "0.24690680307382584 0.9031791956610762\n",
      "495/495 [==============================] - 3s 6ms/step\n",
      "2.068297872785479 0.5090909118604179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[234,  18],\n",
       "       [225,  18]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_6, y=labels_sub_6, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_6, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_6,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_3))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_3, data_sub_3)) \n",
    "    labels_test = np.concatenate((labels_sub_3, labels_sub_3))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=1,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 61s 22ms/step - loss: 0.5683 - acc: 0.6611\n",
      "692/692 [==============================] - 16s 23ms/step\n",
      "0.4936970218765749 0.7413294889635778\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 62s 23ms/step - loss: 0.5324 - acc: 0.6947\n",
      "692/692 [==============================] - 16s 23ms/step\n",
      "0.508745660152787 0.7095375766686965\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 62s 22ms/step - loss: 0.5539 - acc: 0.6904\n",
      "692/692 [==============================] - 16s 24ms/step\n",
      "0.5038750962531894 0.6502890199896573\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 64s 23ms/step - loss: 0.5486 - acc: 0.6774\n",
      "692/692 [==============================] - 16s 24ms/step\n",
      "0.5133207749112407 0.7369942274913622\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 64s 23ms/step - loss: 0.5304 - acc: 0.7030\n",
      "692/692 [==============================] - 19s 27ms/step\n",
      "0.4430420984281227 0.8338150364815156\n",
      "495/495 [==============================] - 4s 7ms/step\n",
      "0.9747477201274549 0.4848484913207064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[204,  48],\n",
       "       [207,  36]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_6, y=labels_sub_6, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_6, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_6,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 66s 24ms/step - loss: 0.6540 - acc: 0.6084\n",
      "692/692 [==============================] - 17s 25ms/step\n",
      "0.5903730901291949 0.573699422611322\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 65s 23ms/step - loss: 0.6588 - acc: 0.5856\n",
      "692/692 [==============================] - 18s 25ms/step\n",
      "0.6515888631171574 0.573699422611322\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 65s 24ms/step - loss: 0.6185 - acc: 0.6203\n",
      "692/692 [==============================] - 17s 25ms/step\n",
      "0.5264895996792145 0.6026011571460377\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 66s 24ms/step - loss: 0.6253 - acc: 0.6283\n",
      "692/692 [==============================] - 18s 25ms/step\n",
      "0.5861526251140702 0.5939306373239597\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 67s 24ms/step - loss: 0.5854 - acc: 0.6665\n",
      "692/692 [==============================] - 22s 32ms/step\n",
      "0.4817157610712541 0.7890173485987104\n",
      "495/495 [==============================] - 4s 8ms/step\n",
      "0.9321833527599922 0.5151515235804548\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[192,  60],\n",
       "       [180,  63]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_6, y=labels_sub_6, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_6, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_6,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  20/2768 [..............................] - ETA: 1:28:33 - loss: 0.9089 - acc: 0.5500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aniketh/.local/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.383740). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 76s 27ms/step - loss: 0.6794 - acc: 0.5679\n",
      "692/692 [==============================] - 20s 29ms/step\n",
      "0.6751169718242105 0.5736994228266568\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 70s 25ms/step - loss: 0.6134 - acc: 0.5957\n",
      "692/692 [==============================] - 18s 26ms/step\n",
      "0.5917933481621604 0.6647398929849181\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 69s 25ms/step - loss: 0.6646 - acc: 0.5773\n",
      "692/692 [==============================] - 18s 27ms/step\n",
      "0.6177328314223042 0.6791907598216065\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 69s 25ms/step - loss: 0.6416 - acc: 0.5950\n",
      "692/692 [==============================] - 19s 27ms/step\n",
      "0.5491762025809357 0.6921965391778877\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 70s 25ms/step - loss: 0.6550 - acc: 0.5773\n",
      "692/692 [==============================] - 19s 27ms/step\n",
      "0.6865103575535593 0.5289017372479329\n",
      "495/495 [==============================] - 4s 8ms/step\n",
      "0.6945596054346874 0.4646464747310889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 68, 184],\n",
       "       [ 81, 162]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_6, y=labels_sub_6, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_6, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_6,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_3))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_3, data_sub_3)) \n",
    "    labels_test = np.concatenate((labels_sub_3, labels_sub_3))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=3,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2796/2796 [==============================] - 73s 26ms/step - loss: 0.4665 - acc: 0.7582\n",
      "700/700 [==============================] - 19s 27ms/step\n",
      "0.30895378320544425 0.8628571466675826\n",
      "Epoch 1/1\n",
      "2796/2796 [==============================] - 72s 26ms/step - loss: 0.4822 - acc: 0.7439\n",
      "700/700 [==============================] - 19s 27ms/step\n",
      "0.24595536126954748 0.9042857197778565\n",
      "Epoch 1/1\n",
      "2797/2797 [==============================] - 72s 26ms/step - loss: 0.4574 - acc: 0.7547\n",
      "699/699 [==============================] - 19s 27ms/step\n",
      "0.1937829755075675 0.9241774002881521\n",
      "Epoch 1/1\n",
      "2797/2797 [==============================] - 73s 26ms/step - loss: 0.4534 - acc: 0.7690\n",
      "699/699 [==============================] - 19s 27ms/step\n",
      "0.21595856958156842 0.9256080154526728\n",
      "Epoch 1/1\n",
      "2798/2798 [==============================] - 73s 26ms/step - loss: 0.4939 - acc: 0.7437\n",
      "698/698 [==============================] - 19s 27ms/step\n",
      "0.22398459237455162 0.9068767957410703\n",
      "459/459 [==============================] - 3s 6ms/step\n",
      "0.684788477576636 0.5773420572800314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[174,  51],\n",
       "       [143,  91]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_7, y=labels_sub_7, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_7, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_7,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_3))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_3, data_sub_3)) \n",
    "    labels_test = np.concatenate((labels_sub_3, labels_sub_3))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=3,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2796/2796 [==============================] - 70s 25ms/step - loss: 0.5782 - acc: 0.6509\n",
      "700/700 [==============================] - 21s 30ms/step\n",
      "0.5461762206895011 0.6971428645508629\n",
      "Epoch 1/1\n",
      "2796/2796 [==============================] - 71s 25ms/step - loss: 0.5324 - acc: 0.6956\n",
      "700/700 [==============================] - 20s 29ms/step\n",
      "0.49628514514437744 0.7557142909084048\n",
      "Epoch 1/1\n",
      "2797/2797 [==============================] - 71s 26ms/step - loss: 0.5454 - acc: 0.6857\n",
      "699/699 [==============================] - 20s 29ms/step\n",
      "0.46343233577043713 0.748211739933883\n",
      "Epoch 1/1\n",
      "2797/2797 [==============================] - 76s 27ms/step - loss: 0.5557 - acc: 0.6747\n",
      "699/699 [==============================] - 20s 29ms/step\n",
      "0.4674393598027581 0.8040057322455407\n",
      "Epoch 1/1\n",
      "2798/2798 [==============================] - 73s 26ms/step - loss: 0.5546 - acc: 0.6823\n",
      "698/698 [==============================] - 21s 30ms/step\n",
      "0.5128757234203781 0.6934097486529446\n",
      "459/459 [==============================] - 3s 7ms/step\n",
      "0.6181746874499685 0.49891068109499864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[190,  35],\n",
       "       [195,  39]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_7, y=labels_sub_7, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_7, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_7,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2796/2796 [==============================] - 39s 14ms/step - loss: 0.6509 - acc: 0.5962\n",
      "700/700 [==============================] - 4s 6ms/step\n",
      "0.5558356375566551 0.5757142862038953\n",
      "Epoch 1/1\n",
      "2796/2796 [==============================] - 35s 12ms/step - loss: 0.6378 - acc: 0.6173\n",
      "700/700 [==============================] - 4s 6ms/step\n",
      "0.5146180419517415 0.7471428667860371\n",
      "Epoch 1/1\n",
      "2797/2797 [==============================] - 35s 12ms/step - loss: 0.6757 - acc: 0.5817\n",
      "699/699 [==============================] - 4s 6ms/step\n",
      "0.5678224484296316 0.6294706785499794\n",
      "Epoch 1/1\n",
      "2797/2797 [==============================] - 35s 12ms/step - loss: 0.6003 - acc: 0.6425\n",
      "699/699 [==============================] - 5s 6ms/step\n",
      "0.5332219218022493 0.7281831275026857\n",
      "Epoch 1/1\n",
      "2798/2798 [==============================] - 36s 13ms/step - loss: 0.6651 - acc: 0.5861\n",
      "698/698 [==============================] - 5s 7ms/step\n",
      "0.5970975378031887 0.6146131854472324\n",
      "459/459 [==============================] - 3s 6ms/step\n",
      "0.5162168633119733 0.7320261542443876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[193,  32],\n",
       "       [ 91, 143]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_7, y=labels_sub_7, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_7, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_7,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2796/2796 [==============================] - 35s 13ms/step - loss: 0.6900 - acc: 0.5583\n",
      "700/700 [==============================] - 5s 7ms/step\n",
      "0.6808065452745983 0.5757142863103322\n",
      "Epoch 1/1\n",
      "2796/2796 [==============================] - 35s 13ms/step - loss: 0.6939 - acc: 0.5526\n",
      "700/700 [==============================] - 5s 7ms/step\n",
      "0.6838896429964474 0.5757142868425165\n",
      "Epoch 1/1\n",
      "2797/2797 [==============================] - 36s 13ms/step - loss: 0.6718 - acc: 0.5856\n",
      "699/699 [==============================] - 5s 7ms/step\n",
      "0.7880655812560574 0.5751072967342382\n",
      "Epoch 1/1\n",
      "2797/2797 [==============================] - 37s 13ms/step - loss: 0.6872 - acc: 0.5695\n",
      "699/699 [==============================] - 5s 7ms/step\n",
      "0.6858353231512596 0.5751072967342382\n",
      "Epoch 1/1\n",
      "2798/2798 [==============================] - 38s 14ms/step - loss: 0.6861 - acc: 0.5690\n",
      "698/698 [==============================] - 5s 7ms/step\n",
      "0.6812407276179524 0.575931232924277\n",
      "459/459 [==============================] - 3s 7ms/step\n",
      "0.7054857657106354 0.49019607846383695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[225,   0],\n",
       "       [234,   0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_7, y=labels_sub_7, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_7, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_7,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_3))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_3, data_sub_3)) \n",
    "    labels_test = np.concatenate((labels_sub_3, labels_sub_3))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=3,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3005/3005 [==============================] - 42s 14ms/step - loss: 0.3938 - acc: 0.8087\n",
      "752/752 [==============================] - 4s 6ms/step\n",
      "0.16368959114682163 0.9335106421816857\n",
      "Epoch 1/1\n",
      "3005/3005 [==============================] - 42s 14ms/step - loss: 0.4420 - acc: 0.7750\n",
      "752/752 [==============================] - 5s 6ms/step\n",
      "0.16997288191603419 0.9414893649914797\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 42s 14ms/step - loss: 0.4301 - acc: 0.7947\n",
      "751/751 [==============================] - 5s 6ms/step\n",
      "0.16461088899436213 0.9374167812807106\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 42s 14ms/step - loss: 0.4761 - acc: 0.7655\n",
      "751/751 [==============================] - 5s 6ms/step\n",
      "0.2618427143522728 0.8801597936969305\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 43s 14ms/step - loss: 0.4565 - acc: 0.7701\n",
      "751/751 [==============================] - 5s 6ms/step\n",
      "0.18343567771489264 0.936085223516675\n",
      "198/198 [==============================] - 1s 6ms/step\n",
      "1.2545231571326954 0.45959596433723815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[79, 11],\n",
       "       [96, 12]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_8, y=labels_sub_8, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_8, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_8,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_3))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_3, data_sub_3)) \n",
    "    labels_test = np.concatenate((labels_sub_3, labels_sub_3))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=3,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3005/3005 [==============================] - 40s 13ms/step - loss: 0.5535 - acc: 0.7008\n",
      "752/752 [==============================] - 6s 7ms/step\n",
      "0.47024956651334154 0.7726063881109052\n",
      "Epoch 1/1\n",
      "3005/3005 [==============================] - 41s 14ms/step - loss: 0.5342 - acc: 0.6975\n",
      "752/752 [==============================] - 6s 7ms/step\n",
      "0.41966782746517023 0.7938829885716451\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 41s 14ms/step - loss: 0.5518 - acc: 0.6790\n",
      "751/751 [==============================] - 6s 8ms/step\n",
      "0.51851703606536 0.7190412887918965\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 41s 14ms/step - loss: 0.5494 - acc: 0.6826\n",
      "751/751 [==============================] - 6s 8ms/step\n",
      "0.4979268148263666 0.7589880236971395\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 42s 14ms/step - loss: 0.5453 - acc: 0.6900\n",
      "751/751 [==============================] - 6s 8ms/step\n",
      "0.4361662690613925 0.7523302302141481\n",
      "198/198 [==============================] - 1s 7ms/step\n",
      "0.7817663819049344 0.44949494994649986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 89,   1],\n",
       "       [108,   0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_8, y=labels_sub_8, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_8, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_8,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3005/3005 [==============================] - 42s 14ms/step - loss: 0.6345 - acc: 0.6183\n",
      "752/752 [==============================] - 6s 8ms/step\n",
      "0.5824044578054801 0.5718085113912821\n",
      "Epoch 1/1\n",
      "3005/3005 [==============================] - 42s 14ms/step - loss: 0.6234 - acc: 0.6136\n",
      "752/752 [==============================] - 6s 8ms/step\n",
      "0.5299788260971137 0.6981383061749821\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 42s 14ms/step - loss: 0.5934 - acc: 0.6397\n",
      "751/751 [==============================] - 6s 8ms/step\n",
      "0.5313540811342907 0.580559254922816\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 42s 14ms/step - loss: 0.5908 - acc: 0.6623\n",
      "751/751 [==============================] - 6s 8ms/step\n",
      "0.5551252430986945 0.7709720460735212\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 43s 14ms/step - loss: 0.6203 - acc: 0.6144\n",
      "751/751 [==============================] - 7s 9ms/step\n",
      "0.5391091385610729 0.6125166467359952\n",
      "198/198 [==============================] - 1s 7ms/step\n",
      "0.689685341234159 0.45454545469597135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 90,   0],\n",
       "       [108,   0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_8, y=labels_sub_8, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_8, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_8,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3005/3005 [==============================] - 48s 16ms/step - loss: 0.6870 - acc: 0.5710\n",
      "752/752 [==============================] - 8s 11ms/step\n",
      "0.6863450138492787 0.5718085115894358\n",
      "Epoch 1/1\n",
      "3005/3005 [==============================] - 48s 16ms/step - loss: 0.6879 - acc: 0.5697\n",
      "752/752 [==============================] - 8s 11ms/step\n",
      "0.6872497473229119 0.5718085115894358\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 48s 16ms/step - loss: 0.6573 - acc: 0.6131\n",
      "751/751 [==============================] - 8s 11ms/step\n",
      "0.8856602629991409 0.5712383498205802\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 49s 16ms/step - loss: 0.6760 - acc: 0.5682\n",
      "751/751 [==============================] - 9s 11ms/step\n",
      "0.5908562288620818 0.5712383497213714\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 50s 16ms/step - loss: 0.6834 - acc: 0.5689\n",
      "751/751 [==============================] - 9s 12ms/step\n",
      "0.674903326202804 0.5712383496221626\n",
      "198/198 [==============================] - 1s 7ms/step\n",
      "0.7467299738917688 0.45454545469597135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 90,   0],\n",
       "       [108,   0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_9, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_8, y=labels_sub_8, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_8, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_8,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_3))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_3, data_sub_3)) \n",
    "    labels_test = np.concatenate((labels_sub_3, labels_sub_3))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=3,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_3))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_3, data_sub_3)) \n",
    "    labels_test = np.concatenate((labels_sub_3, labels_sub_3))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=3,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 43s 15ms/step - loss: 0.4328 - acc: 0.7924\n",
      "705/705 [==============================] - 5s 8ms/step\n",
      "0.16462874548106804 0.9418439739350731\n",
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 42s 15ms/step - loss: 0.4750 - acc: 0.7431\n",
      "705/705 [==============================] - 5s 8ms/step\n",
      "0.19416080419377074 0.9205673804097142\n",
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 43s 15ms/step - loss: 0.4180 - acc: 0.7956\n",
      "705/705 [==============================] - 6s 8ms/step\n",
      "0.17091983857280607 0.9361702163591452\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 44s 15ms/step - loss: 0.4886 - acc: 0.7464\n",
      "704/704 [==============================] - 6s 8ms/step\n",
      "0.24465082477763644 0.8906250041909516\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 44s 16ms/step - loss: 0.3825 - acc: 0.8109\n",
      "704/704 [==============================] - 6s 8ms/step\n",
      "0.17726293171067067 0.9318181853741407\n",
      "432/432 [==============================] - 3s 6ms/step\n",
      "0.7055725942556348 0.6435185238994934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[193,   9],\n",
       "       [145,  85]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_8, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_9, y=labels_sub_9, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_9, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_9,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 43s 15ms/step - loss: 0.5505 - acc: 0.6863\n",
      "705/705 [==============================] - 7s 9ms/step\n",
      "0.4877724530479164 0.7943262501177213\n",
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 43s 15ms/step - loss: 0.5795 - acc: 0.6455\n",
      "705/705 [==============================] - 7s 9ms/step\n",
      "0.5294553481095227 0.7035461082948861\n",
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 43s 15ms/step - loss: 0.5633 - acc: 0.6707\n",
      "705/705 [==============================] - 7s 10ms/step\n",
      "0.5210294700260704 0.7319149018813532\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 43s 15ms/step - loss: 0.5919 - acc: 0.6364\n",
      "704/704 [==============================] - 7s 10ms/step\n",
      "0.5584419684971429 0.6974431917452338\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 44s 15ms/step - loss: 0.5916 - acc: 0.6414\n",
      "704/704 [==============================] - 7s 10ms/step\n",
      "0.486122649655127 0.7812500097577206\n",
      "432/432 [==============================] - 3s 7ms/step\n",
      "0.5018949090434169 0.7615740848705173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[174,  28],\n",
       "       [ 75, 155]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_8, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_9, y=labels_sub_9, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_9, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_9,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 44s 16ms/step - loss: 0.6094 - acc: 0.6270\n",
      "705/705 [==============================] - 7s 10ms/step\n",
      "0.5434171909875903 0.5773049653210538\n",
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 44s 16ms/step - loss: 0.6337 - acc: 0.6299\n",
      "705/705 [==============================] - 7s 11ms/step\n",
      "0.6252202875647984 0.5773049652153719\n",
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 45s 16ms/step - loss: 0.6491 - acc: 0.5912\n",
      "705/705 [==============================] - 7s 11ms/step\n",
      "0.5262450823124419 0.7319149021983992\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 46s 16ms/step - loss: 0.6153 - acc: 0.6343\n",
      "704/704 [==============================] - 8s 11ms/step\n",
      "0.5504302204247903 0.7343750070272521\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 46s 16ms/step - loss: 0.6152 - acc: 0.6261\n",
      "704/704 [==============================] - 8s 11ms/step\n",
      "0.5591679873918607 0.7997159188274633\n",
      "432/432 [==============================] - 3s 7ms/step\n",
      "0.5568248963466397 0.7893518618204527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[181,  21],\n",
       "       [ 70, 160]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_8, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_9, y=labels_sub_9, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_9, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_9,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 48s 17ms/step - loss: 0.6822 - acc: 0.5717\n",
      "705/705 [==============================] - 9s 12ms/step\n",
      "0.6808978640441353 0.5758865255836054\n",
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 47s 17ms/step - loss: 0.6657 - acc: 0.5660\n",
      "705/705 [==============================] - 9s 12ms/step\n",
      "0.6812608859217759 0.5773049651096899\n",
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 47s 17ms/step - loss: 0.6544 - acc: 0.5887\n",
      "705/705 [==============================] - 9s 13ms/step\n",
      "0.6258801145756498 0.5773049656380999\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 48s 17ms/step - loss: 0.6565 - acc: 0.5821\n",
      "704/704 [==============================] - 9s 13ms/step\n",
      "0.6760460699654438 0.5994318222246048\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 49s 17ms/step - loss: 0.6874 - acc: 0.5630\n",
      "704/704 [==============================] - 9s 13ms/step\n",
      "0.6871762769296765 0.5781250004868277\n",
      "432/432 [==============================] - 3s 7ms/step\n",
      "0.7472728514974868 0.4675925925925926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[202,   0],\n",
       "       [230,   0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_8, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_10))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_9, y=labels_sub_9, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_9, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_9,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_3))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_3, data_sub_3)) \n",
    "    labels_test = np.concatenate((labels_sub_3, labels_sub_3))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=3,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_4, data_sub_5,\n",
    "                                data_sub_6, data_sub_7, data_sub_8 , data_sub_9, data_sub_10), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_4, labels_sub_5, \n",
    "                                  labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9, labels_sub_10))\n",
    "\n",
    "limit = math.ceil(len(data_training)/len(data_sub_3))\n",
    "\n",
    "for i in range(limit):\n",
    "    data_test = np.concatenate((data_sub_3, data_sub_3)) \n",
    "    labels_test = np.concatenate((labels_sub_3, labels_sub_3))\n",
    "    \n",
    "IMG_SIZE = 100\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = \"softmax\"))\n",
    "\n",
    "model.compile(\n",
    " optimizer = \"adam\",\n",
    " loss = \"binary_crossentropy\",\n",
    " metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(x=data_training, y=labels_training, batch_size=5, epochs=3,\n",
    "     verbose=1, shuffle=True)\n",
    "loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "\n",
    "print(loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 50s 17ms/step - loss: 0.4895 - acc: 0.7477\n",
      "739/739 [==============================] - 8s 11ms/step\n",
      "0.24100348597558793 0.8917456076093553\n",
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 51s 17ms/step - loss: 0.4746 - acc: 0.7535\n",
      "739/739 [==============================] - 8s 11ms/step\n",
      "0.4216222252132162 0.7848443914411516\n",
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 51s 17ms/step - loss: 0.4846 - acc: 0.7477\n",
      "739/739 [==============================] - 9s 12ms/step\n",
      "0.2678469107462678 0.8619756485677056\n",
      "Epoch 1/1\n",
      "2954/2954 [==============================] - 52s 18ms/step - loss: 0.4250 - acc: 0.7800\n",
      "738/738 [==============================] - 9s 12ms/step\n",
      "0.23688486632121206 0.8983739890905253\n",
      "Epoch 1/1\n",
      "2955/2955 [==============================] - 53s 18ms/step - loss: 0.4386 - acc: 0.7750\n",
      "737/737 [==============================] - 9s 12ms/step\n",
      "0.17461989367417227 0.9294436948432042\n",
      "263/263 [==============================] - 1s 5ms/step\n",
      "0.26801446313746696 0.8897338465366074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[234,  29],\n",
       "       [  0,   0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_8, data_sub_9), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_10, y=labels_sub_10, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_10, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_10,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 45s 15ms/step - loss: 0.5572 - acc: 0.6864\n",
      "739/739 [==============================] - 9s 12ms/step\n",
      "0.4635425429030023 0.790257113167817\n",
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 45s 15ms/step - loss: 0.5337 - acc: 0.7044\n",
      "739/739 [==============================] - 9s 12ms/step\n",
      "0.4516641339999989 0.8173207111344124\n",
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 47s 16ms/step - loss: 0.5464 - acc: 0.6966\n",
      "739/739 [==============================] - 9s 12ms/step\n",
      "0.4446430984224131 0.8119079911821749\n",
      "Epoch 1/1\n",
      "2954/2954 [==============================] - 47s 16ms/step - loss: 0.5602 - acc: 0.6845\n",
      "738/738 [==============================] - 9s 13ms/step\n",
      "0.5038323996634018 0.7831978413672628\n",
      "Epoch 1/1\n",
      "2955/2955 [==============================] - 49s 17ms/step - loss: 0.5792 - acc: 0.6619\n",
      "737/737 [==============================] - 10s 13ms/step\n",
      "0.5065444362813574 0.6879240235609472\n",
      "263/263 [==============================] - 2s 6ms/step\n",
      "0.3446473052066542 0.8555133160302848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[225,  38],\n",
       "       [  0,   0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_8, data_sub_9), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_10, y=labels_sub_10, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_10, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_10,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 48s 16ms/step - loss: 0.6701 - acc: 0.5842\n",
      "739/739 [==============================] - 10s 13ms/step\n",
      "0.6736360498186055 0.5548037908396637\n",
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 47s 16ms/step - loss: 0.6463 - acc: 0.6136\n",
      "739/739 [==============================] - 10s 13ms/step\n",
      "0.5586559347435328 0.7077131339919744\n",
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 47s 16ms/step - loss: 0.6527 - acc: 0.5855\n",
      "739/739 [==============================] - 10s 14ms/step\n",
      "0.6301046496557124 0.6630581947439256\n",
      "Epoch 1/1\n",
      "2954/2954 [==============================] - 47s 16ms/step - loss: 0.6874 - acc: 0.5680\n",
      "738/738 [==============================] - 10s 14ms/step\n",
      "0.8318833518864178 0.5352303528486875\n",
      "Epoch 1/1\n",
      "2955/2955 [==============================] - 48s 16ms/step - loss: 0.6533 - acc: 0.5838\n",
      "737/737 [==============================] - 10s 14ms/step\n",
      "0.6125653190803657 0.5318860253331781\n",
      "263/263 [==============================] - 2s 6ms/step\n",
      "0.5053572570869678 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[263]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_8, data_sub_9), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_10, y=labels_sub_10, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_10, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_10,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 48s 16ms/step - loss: 0.6926 - acc: 0.5516\n",
      "739/739 [==============================] - 10s 14ms/step\n",
      "0.694204522243856 0.5345060905398793\n",
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 49s 16ms/step - loss: 0.6757 - acc: 0.5909\n",
      "739/739 [==============================] - 11s 14ms/step\n",
      "0.6709630754706986 0.5290933715756756\n",
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 49s 17ms/step - loss: 0.6831 - acc: 0.5601\n",
      "739/739 [==============================] - 11s 15ms/step\n",
      "0.6761167038922703 0.711772675886851\n",
      "Epoch 1/1\n",
      "2954/2954 [==============================] - 49s 17ms/step - loss: 0.6864 - acc: 0.5660\n",
      "738/738 [==============================] - 11s 15ms/step\n",
      "0.6888063487402469 0.5352303531515566\n",
      "Epoch 1/1\n",
      "2955/2955 [==============================] - 50s 17ms/step - loss: 0.6892 - acc: 0.5465\n",
      "737/737 [==============================] - 11s 15ms/step\n",
      "0.7076733305625709 0.5345997293776702\n",
      "263/263 [==============================] - 2s 6ms/step\n",
      "0.4659696926182214 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[263]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_training = np.concatenate((data_sub_2, data_sub_1, data_sub_3, data_sub_4,\n",
    "                                data_sub_5, data_sub_6, data_sub_7 , data_sub_8, data_sub_9), axis = 0)\n",
    "labels_training = np.concatenate((labels_sub_2, labels_sub_1, labels_sub_3, labels_sub_4, \n",
    "                                  labels_sub_5, labels_sub_6, labels_sub_7, labels_sub_8, labels_sub_9))\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \n",
    "    IMG_SIZE = 100\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(filters = 5, kernel_size = (5,5),padding = 'Same', \n",
    "                     activation ='relu', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(\n",
    "     optimizer = \"adam\",\n",
    "     loss = \"binary_crossentropy\",\n",
    "     metrics = [\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_evaluate(model, data_train, labels_train, data_test, labels_test):\n",
    "    model.fit(x=data_train, y=labels_train, batch_size=5, epochs=1,\n",
    "         verbose=1, shuffle=True)\n",
    "    loss, acc = model.evaluate(x=data_test, y=labels_test, batch_size=5, verbose=1)\n",
    "    print(loss, acc)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "load_model()\n",
    "kFold = StratifiedKFold(n_splits=5, shuffle = True)\n",
    "for train, test in kFold.split(data_training,labels_training):\n",
    "    model = None\n",
    "    model = load_model()\n",
    "    train_evaluate(model, data_training[train], labels_training[train], data_training[test], labels_training[test])\n",
    "\n",
    "\n",
    "loss, acc = model.evaluate(x=data_sub_10, y=labels_sub_10, batch_size=5, verbose=1)\n",
    "print(loss, acc)\n",
    "y_pred = model.predict(data_sub_10, verbose=0)\n",
    "y_pred = np.array([int(round(i[0])) for i in y_pred])\n",
    "confusion_matrix(labels_sub_10,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
